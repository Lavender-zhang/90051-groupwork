{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "484efd83-4294-4f68-bd6b-2b794ef7201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as tvm\n",
    "import timm\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e034c15b-2ecd-4abb-8b36-fcb2355e2d4f",
   "metadata": {},
   "source": [
    "### check the picture size if at least 100*100 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cf6f74e-3454-4713-8fd5-703a604c5fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "picture width: 1024, and height: 768\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "# open the file\n",
    "img = Image.open(\"Animals_with_Attributes2/JPEGImages/antelope/antelope_10002.jpg\")  \n",
    "width, height = img.size\n",
    "print(f\"picture width: {width}, and height: {height}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d5e083-9695-40b9-ae0f-edbb943cd408",
   "metadata": {},
   "source": [
    "# Part1 loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02639e47-8e4c-4393-81d6-3821b38fef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the ori. dataset(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2904d2e1-30b3-4f76-b345-3ce55081e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG = 224  #standard size\n",
    "tfm = transforms.Compose([\n",
    "    transforms.Resize((IMG, IMG)),\n",
    "    transforms.ToTensor(),\n",
    "    #for better using resnet as preprocessing part\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60a97e48-ea4a-4b63-8032-221f3d100ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf Animals_with_Attributes2/JPEGImages/.ipynb_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e320a207-41b4-4bb4-9e60-55aaab84e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#loading the whole dataset\n",
    "import os\n",
    "whole_ds = datasets.ImageFolder(\"Animals_with_Attributes2/JPEGImages\", transform=tfm)\n",
    "whole_dl = DataLoader(whole_ds, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca171d2e-631e-4992-a64a-c7ca8334bb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37315\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "#check\n",
    "print(len(whole_ds))       # numbers of pictures\n",
    "print(len(whole_ds.classes)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "822549d7-0254-4dc0-8a57-5ff899329a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2).to(device).eval()\n",
    "feature_extractor = nn.Sequential(*list(resnet.children())[:-1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d715ef64-fa02-435c-9ce8-1e5c8e04e6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: torch.Size([37305, 2048]) y_test: torch.Size([37305])\n"
     ]
    }
   ],
   "source": [
    "feats, labels = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, lbls in whole_dl:\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        f = feature_extractor(imgs)              # [B, 2048, 1, 1]\n",
    "        f = f.squeeze(-1).squeeze(-1).cpu()      # [B, 2048]\n",
    "        feats.append(f)\n",
    "        labels.append(lbls)\n",
    "\n",
    "X_test = torch.cat(feats, 0)        # [N, 2048]  —— ResNet 特征\n",
    "y_test = torch.cat(labels, 0)       # [N]        —— 标签(0~49)\n",
    "print(\"X_test:\", X_test.shape, \"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61e429ef-761d-4ecb-94cb-864a1c34082a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_whole.shape: torch.Size([37305, 2049])\n"
     ]
    }
   ],
   "source": [
    "test_whole = torch.cat([X_test, y_test.unsqueeze(1)], dim=1)\n",
    "print(\"test_whole.shape:\", test_whole.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9343af9-acd5-46ce-a324-8fbc68df997d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 3.8338e-02, 0.0000e+00,  ..., 0.0000e+00, 1.6849e-03,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        ...,\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.2317e-01,\n",
       "         4.9000e+01],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0546e-02, 0.0000e+00,\n",
       "         4.9000e+01],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         4.9000e+01]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00079c19-833d-4036-8743-a9a58ea9dc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def read_title_and_desc_clean(txt_path):\n",
    "    \"\"\"读取 AwA2 licenses txt 文件中的 TITLE 和 DESCRIPTION 字段（去掉符号框线）\"\"\"\n",
    "    title, desc = \"\", \"\"\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    clean = lambda s: re.sub(r'[\\+\\-\\|\\_]+', '', s).strip()  # 删除 + - | _\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if \"TITLE\" in line.upper() and i + 1 < len(lines):\n",
    "            title = clean(lines[i + 1])\n",
    "        if \"DESCRIPTION\" in line.upper():\n",
    "            desc_lines = []\n",
    "            for j in range(i + 1, len(lines)):\n",
    "                if any(k in lines[j].upper() for k in [\"TITLE\", \"INFO\", \"TAGS\", \"PHOTOGRAPHER\", \"LICENSE\"]):\n",
    "                    break\n",
    "                desc_lines.append(clean(lines[j]))\n",
    "            desc = \" \".join(desc_lines).strip()\n",
    "            break\n",
    "    return title, desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f058193-9edd-43ae-a7a9-a24f44e3272d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: \n",
      "DESCRIPTION: You are free to use this photo  (including commercial use) under attribution to the author. If being used online please add a link to <a href=\"http://ujora.de\" rel=\"nofollow\">ujora.de</a> Dieses Foto  ...\n"
     ]
    }
   ],
   "source": [
    "#check\n",
    "txt_path = \"Animals_with_Attributes2/licenses/antelope/antelope_10021.txt\"\n",
    "title, desc = read_title_and_desc_clean(txt_path)\n",
    "print(\"TITLE:\", title)\n",
    "print(\"DESCRIPTION:\", desc[:200], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a796f36b-66e8-49fc-977b-605fb40c77ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "行数(应为50): 50\n",
      "   label       class  n_txt\n",
      "0    0.0    antelope   1046\n",
      "1    1.0         bat    178\n",
      "2    2.0      beaver    147\n",
      "3    3.0  blue+whale    174\n",
      "4    4.0      bobcat    627\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "IMG_ROOT = \"Animals_with_Attributes2/JPEGImages\"\n",
    "TXT_ROOT = \"Animals_with_Attributes2/licenses\"\n",
    "\n",
    "# 用于与标签对齐（确保顺序和 y_test 的 0..49 一致）\n",
    "class_to_idx = datasets.ImageFolder(IMG_ROOT).class_to_idx  # {'antelope':0, ...}\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "# 读取并清洗单个 txt 的 TITLE 和 DESCRIPTION（去掉框线/下划线/HTML标签）\n",
    "def read_title_and_desc_clean(p):\n",
    "    title, desc = \"\", \"\"\n",
    "    clean = lambda s: re.sub(r'[\\+\\-\\|\\_]+', '', s).strip()\n",
    "    with open(p, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        U = line.upper()\n",
    "        if \"TITLE\" in U and i + 1 < len(lines):\n",
    "            title = clean(lines[i + 1])\n",
    "        if \"DESCRIPTION\" in U:\n",
    "            buf = []\n",
    "            for j in range(i + 1, len(lines)):\n",
    "                if any(k in lines[j].upper() for k in [\"TITLE\",\"INFO\",\"TAGS\",\"PHOTOGRAPHER\",\"LICENSE\"]):\n",
    "                    break\n",
    "                buf.append(clean(lines[j]))\n",
    "            desc = \" \".join(buf).strip()\n",
    "            break\n",
    "    # 去掉 HTML 标签\n",
    "    title = re.sub(r\"<.*?>\", \"\", title)\n",
    "    desc  = re.sub(r\"<.*?>\", \"\", desc)\n",
    "    return title, desc\n",
    "\n",
    "# 按类别汇总：每个子文件夹 -> 拼接所有 txt 的 title+desc\n",
    "rows = []\n",
    "for cls in sorted(os.listdir(TXT_ROOT)):\n",
    "    cls_dir = os.path.join(TXT_ROOT, cls)\n",
    "    if not os.path.isdir(cls_dir):\n",
    "        continue\n",
    "    pieces = []\n",
    "    for fname in sorted(os.listdir(cls_dir)):\n",
    "        if fname.endswith(\".txt\"):\n",
    "            t, d = read_title_and_desc_clean(os.path.join(cls_dir, fname))\n",
    "            text = \" \".join([t, d]).strip()\n",
    "            if text:\n",
    "                pieces.append(text)\n",
    "    merged = \" \".join(pieces)              # 该类别的整合文本\n",
    "    rows.append({\"class\": cls, \"text\": merged, \"n_txt\": len(pieces)})\n",
    "\n",
    "# 变成 DataFrame，并按 label 顺序(0..49) 排好，方便与 y_test 对齐\n",
    "df = pd.DataFrame(rows)\n",
    "df[\"label\"] = df[\"class\"].map(class_to_idx)\n",
    "df = df.sort_values(\"label\").reset_index(drop=True)\n",
    "df = df.iloc[:-1].reset_index(drop=True)\n",
    "print(\"行数(应为50):\", len(df))\n",
    "print(df[[\"label\",\"class\",\"n_txt\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "97d598eb-c0f9-4c02-b997-4b7b37af5c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>n_txt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>antelope</td>\n",
       "      <td>\\And God said, Let the earth bring forth the l...</td>\n",
       "      <td>1046</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bat</td>\n",
       "      <td>Found below the power lines at Hamilton Beach....</td>\n",
       "      <td>178</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beaver</td>\n",
       "      <td>the local beavers on Christmas day 2007 (no de...</td>\n",
       "      <td>147</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blue+whale</td>\n",
       "      <td>(no description) Free Fall breaching. (no desc...</td>\n",
       "      <td>174</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bobcat</td>\n",
       "      <td>One of the cubs walking in the enclosure, unde...</td>\n",
       "      <td>627</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        class                                               text  n_txt  label\n",
       "0    antelope  \\And God said, Let the earth bring forth the l...   1046    0.0\n",
       "1         bat  Found below the power lines at Hamilton Beach....    178    1.0\n",
       "2      beaver  the local beavers on Christmas day 2007 (no de...    147    2.0\n",
       "3  blue+whale  (no description) Free Fall breaching. (no desc...    174    3.0\n",
       "4      bobcat  One of the cubs walking in the enclosure, unde...    627    4.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fda04911-a0de-4b34-88fb-859f070ee06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape: (50, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 你已经有 df（50行），每行是一个类别的 text\n",
    "texts = df[\"text\"].fillna(\"\").tolist()\n",
    "\n",
    "# 1) 定义 TF-IDF 模型\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=1000,       # 取前1000个高频特征，可调\n",
    "    stop_words=\"english\",    # 去除英文停用词\n",
    "    lowercase=True           # 全部转小写\n",
    ")\n",
    "\n",
    "# 2) 拟合并变换\n",
    "X_tfidf = tfidf.fit_transform(texts)      # shape (50, vocab_size)\n",
    "print(\"TF-IDF shape:\", X_tfidf.shape)\n",
    "\n",
    "# 3) 转成 torch.Tensor，方便和你的 test_whole 拼接\n",
    "X_tfidf_tensor = torch.tensor(X_tfidf.toarray(), dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a247dcdb-5403-4e4c-9c72-0bf7f49d78fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0111, 0.0000, 0.0000,  ..., 0.0000, 0.0027, 0.0033],\n",
       "        [0.0000, 0.0106, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0274, 0.0000],\n",
       "        [0.0031, 0.0000, 0.0000,  ..., 0.0097, 0.0038, 0.0323],\n",
       "        [0.0032, 0.0000, 0.0000,  ..., 0.0068, 0.0000, 0.0024]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a71e11ce-3aa7-4d92-a58f-6191658aeb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "融合后形状: torch.Size([37305, 3048])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1) 拆出图片特征与标签\n",
    "X_img = test_whole[:, :-1]       # [37305, 2048]\n",
    "y_img = test_whole[:, -1].long() # [37305] 取整型标签\n",
    "\n",
    "# 2) TF-IDF 向量 (50, 1000)\n",
    "X_tfidf_tensor = X_tfidf_tensor  # 你上面生成的\n",
    "\n",
    "# 3) 为每张图片找到对应类别的 TF-IDF\n",
    "#    用标签直接索引即可（PyTorch 的广播机制会自动复制）\n",
    "X_text = X_tfidf_tensor[y_img]   # [37305, 1000]\n",
    "\n",
    "# 4) 拼接图像特征 + 文本特征\n",
    "X_combined = torch.cat([X_img, X_text], dim=1)  # [37305, 2048+1000=3048]\n",
    "print(\"融合后形状:\", X_combined.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "80f2e094-e6e3-4d14-b2c2-b3e1af1d9b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0383, 0.0000,  ..., 0.0000, 0.0027, 0.0033],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0027, 0.0033],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0027, 0.0033],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0068, 0.0000, 0.0024],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0068, 0.0000, 0.0024],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0068, 0.0000, 0.0024]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d6cff2f0-4904-4867-a99f-4f66da0e32b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  ..., 49, 49, 49])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a3449abb-1485-498e-b841-7db490037a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold1: torch.Size([2427, 3048]) [0, 1, 2, 3, 4] | train&val: torch.Size([34878, 3048])\n",
      "✅ 已生成并保存 10 折（按类分组）\n"
     ]
    }
   ],
   "source": [
    "#k=10 10折交叉验证\n",
    "import torch\n",
    "\n",
    "# 你已有：\n",
    "# X_combined: [N, D]  例如 3048 维（2048图像 + 1000文本）\n",
    "# y_img:      [N]     标签 0..49\n",
    "X = X_combined\n",
    "y = y_img.long()\n",
    "\n",
    "assert y.min().item() == 0 and y.max().item() == 49, \"y 应为 0..49 的类别索引\"\n",
    "\n",
    "folds = {}\n",
    "classes_per_fold = 5\n",
    "num_classes = 50\n",
    "num_folds = num_classes // classes_per_fold  # 10\n",
    "\n",
    "for i in range(1, num_folds + 1):\n",
    "    # 本折测试的类别（按标签顺序：0..4, 5..9, ...）\n",
    "    test_classes = list(range((i-1)*classes_per_fold, i*classes_per_fold))\n",
    "    test_mask  = torch.isin(y, torch.tensor(test_classes, dtype=torch.long))\n",
    "    train_mask = ~test_mask\n",
    "\n",
    "    X_test  = X[test_mask]\n",
    "    y_test  = y[test_mask]\n",
    "    X_trval = X[train_mask]\n",
    "    y_trval = y[train_mask]\n",
    "\n",
    "    folds[f\"X_test_{i}\"]         = X_test\n",
    "    folds[f\"y_test_{i}\"]         = y_test\n",
    "    folds[f\"X_train&val_{i}\"]    = X_trval\n",
    "    folds[f\"y_train&val_{i}\"]    = y_trval\n",
    "    folds[f\"test_classes_{i}\"]   = torch.tensor(test_classes)  # 记录本折的类\n",
    "\n",
    "# 看一眼第1折\n",
    "print(\"fold1:\", folds[\"X_test_1\"].shape, folds[\"y_test_1\"].unique().tolist(),\n",
    "      \"| train&val:\", folds[\"X_train&val_1\"].shape)\n",
    "\n",
    "# （可选）保存所有折\n",
    "torch.save(folds, \"awa2_classwise_10folds.pt\")\n",
    "print(\"✅ 已生成并保存 10 折（按类分组）\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8c2f56a1-392e-48b5-a4fc-725128dda765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold2: torch.Size([4556, 3048]) [5, 6, 7, 8, 9] | train&val: torch.Size([32749, 3048]) torch.Size([32749])\n"
     ]
    }
   ],
   "source": [
    "print(\"fold2:\", folds[\"X_test_2\"].shape, folds[\"y_test_2\"].unique().tolist(),\n",
    "      \"| train&val:\", folds[\"X_train&val_2\"].shape, folds[\"y_train&val_2\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "247e82e2-3d01-43ba-ac4f-5c69f62f89ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update train&val set(about preprocessing that rotation, 高斯noise，....） for better performance \n",
    "#......."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8e7f9225-cc92-4a2f-85a6-26a7432b0d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: acc=0.4314\n",
      "Fold 2: acc=0.2935\n",
      "Fold 3: acc=0.2286\n",
      "Fold 4: acc=0.0856\n",
      "Fold 5: acc=0.4046\n",
      "Fold 6: acc=0.3735\n",
      "Fold 7: acc=0.1940\n",
      "Fold 8: acc=0.2245\n",
      "Fold 9: acc=0.1259\n",
      "Fold 10: acc=0.4886\n",
      "Mean acc: 0.28501834720373154\n"
     ]
    }
   ],
   "source": [
    "#mlp（多层感知机）\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# 假设你已有：\n",
    "# folds: {\"X_train&val_1\":..., \"y_train&val_1\":..., \"X_test_1\":..., \"y_test_1\":..., \"test_classes_1\": tensor([0,1,2,3,4]), ...}\n",
    "# X_tfidf_tensor: [50, V]  每个类别的 TF-IDF 语义向量（例如 V=1000）\n",
    "\n",
    "S = X_tfidf_tensor.float()               # 语义矩阵 [50, V]\n",
    "V = S.shape[1]                           # 语义维度（TF-IDF 特征数）\n",
    "num_folds = 10\n",
    "accs = []\n",
    "\n",
    "for i in range(1, num_folds + 1):\n",
    "    # 1) 取出本折的训练/测试数据\n",
    "    Xtr_all = folds[f\"X_train&val_{i}\"]  # [Ntr, 3048] 你之前的“图像+文本”拼接\n",
    "    ytr     = folds[f\"y_train&val_{i}\"].long()\n",
    "    Xte_all = folds[f\"X_test_{i}\"]       # [Nte, 3048]\n",
    "    yte     = folds[f\"y_test_{i}\"].long()\n",
    "    unseen  = folds[f\"test_classes_{i}\"].long()  # 本折的 unseen 类标签（长度=5）\n",
    "\n",
    "    # ✅ 关键：MLP 的输入只用图像特征（前 2048 维）\n",
    "    Xtr = Xtr_all[:, :2048].float()\n",
    "    Xte = Xte_all[:, :2048].float()\n",
    "\n",
    "    # 训练目标：每个训练样本对应的类别语义向量（用 y 索引 S）\n",
    "    Ytr = S[ytr]  # [Ntr, V]\n",
    "\n",
    "    # 2) 定义一个很小的 MLP 做映射：2048 → V（如 1000）\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(2048, 1024),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(1024, V)\n",
    "    )\n",
    "    opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    # 3) 训练若干 epoch（可调）\n",
    "    model.train()\n",
    "    for _ in range(10):\n",
    "        opt.zero_grad()\n",
    "        pred = model(Xtr)       # [Ntr, V]\n",
    "        loss = loss_fn(pred, Ytr)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    # 4) Zero-shot 测试：与 unseen 类语义做相似度匹配\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred_sem = model(Xte)                   # [Nte, V]\n",
    "        # 用余弦相似度更稳：先 L2 归一化\n",
    "        pred_sem  = F.normalize(pred_sem, dim=1)\n",
    "        unseen_S  = F.normalize(S[unseen], dim=1)   # [5, V]\n",
    "        sims      = pred_sem @ unseen_S.T          # [Nte, 5]\n",
    "        pred_lbl  = unseen[sims.argmax(dim=1)]     # 取相似度最大的 unseen 类\n",
    "        acc       = (pred_lbl == yte).float().mean().item()\n",
    "        accs.append(acc)\n",
    "        print(f\"Fold {i}: acc={acc:.4f}\")\n",
    "\n",
    "print(\"Mean acc:\", sum(accs)/len(accs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "736c6e5f-5a99-4ba7-9f52-48a8c04a5597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param combos = 9  -> [(512, 0.001), (512, 0.0005), (512, 0.0001), (1024, 0.001), (1024, 0.0005), (1024, 0.0001), (2048, 0.001), (2048, 0.0005), (2048, 0.0001)]\n"
     ]
    }
   ],
   "source": [
    "#调超参数\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import itertools, random\n",
    "\n",
    "# ===== 前提：你已经准备好 =====\n",
    "# folds: dict，包含每折的数据：\n",
    "#   \"X_train&val_i\", \"y_train&val_i\", \"X_test_i\", \"y_test_i\", \"test_classes_i\"\n",
    "# S: [50, V]  每个类别的语义向量（TF-IDF），且已为 float32\n",
    "S = X_tfidf_tensor.float() if 'X_tfidf_tensor' in globals() else S\n",
    "V = S.shape[1]\n",
    "num_outer = 10\n",
    "k_inner = 3\n",
    "\n",
    "# ===== 超参数网格（每个3个取值，符合要求）=====\n",
    "param_grid = {\n",
    "    \"hidden_dim\": [512, 1024, 2048],     # 低/中/高\n",
    "    \"lr\":         [1e-3, 5e-4, 1e-4],    # 低/中/高\n",
    "}\n",
    "param_list = list(itertools.product(*param_grid.values()))\n",
    "print(f\"Param combos = {len(param_list)}  -> {param_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6e351e79-3fc1-4103-9403-4d835259b0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hidden_dim):\n",
    "    \"\"\"MLP: 2048 -> hidden_dim -> V\"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(2048, hidden_dim),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_dim, V)\n",
    "    )\n",
    "\n",
    "def train_epoch(model, opt, Xtr, Ytr, loss_fn):\n",
    "    opt.zero_grad()\n",
    "    pred = model(Xtr)\n",
    "    loss = loss_fn(pred, Ytr)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    return loss.item()\n",
    "\n",
    "def zsl_accuracy(model, X, y_true, candidate_classes, S):\n",
    "    \"\"\"\n",
    "    Zero-shot 评估：把 X 映射到语义空间，与 candidate_classes 的类原型做余弦匹配。\n",
    "    candidate_classes: 1D tensor（内层为 val 类；外层为 unseen 类）\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        pred_sem = F.normalize(model(X), dim=1)               # [N, V]\n",
    "        proto    = F.normalize(S[candidate_classes], dim=1)   # [C, V]\n",
    "        sims     = pred_sem @ proto.T                         # [N, C]\n",
    "        pred_lbl = candidate_classes[sims.argmax(dim=1)]\n",
    "        acc      = (pred_lbl == y_true).float().mean().item()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "12f9e5c2-5382-4072-9ced-f07fe26da534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#调参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d57295-5f53-45b6-b1a1-5cdb6e2d0e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50190a37-4d73-487b-89de-cc46c3808984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f-CLSWGAN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
