{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3dac5fe-27b1-4e3d-8def-2632f417f983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as tvm\n",
    "import timm\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torchvision.models as models\n",
    "from torchvision.models import ResNet50_Weights \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdcbb10-7b1a-40c8-bd89-0e1ed9edf3d1",
   "metadata": {},
   "source": [
    "### check the picture size if at least 100*100 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d068313-634c-4953-b107-9a18ddea574c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "picture width: 1024, and height: 768\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "# open the file\n",
    "img = Image.open(\"Animals_with_Attributes2/JPEGImages/antelope/antelope_10002.jpg\")  \n",
    "width, height = img.size\n",
    "print(f\"picture width: {width}, and height: {height}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845d2c23-661a-4d9d-b82a-597450b27656",
   "metadata": {},
   "source": [
    "# Part1 loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11ae74e4-9f7c-499f-92f3-095e16e1c8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fdfaad869c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, math, random, torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms as T, models\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True  # 兜底\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ResNet50 冻结为 2048 维特征\n",
    "try:\n",
    "    from torchvision.models import ResNet50_Weights\n",
    "    resnet = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "    preprocess_eval = ResNet50_Weights.IMAGENET1K_V2.transforms()\n",
    "except Exception:\n",
    "    resnet = models.resnet50(pretrained=True)\n",
    "    preprocess_eval = T.Compose([\n",
    "        T.Resize((224,224)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "    ])\n",
    "resnet.fc = nn.Identity()\n",
    "resnet = resnet.to(device).eval()\n",
    "torch.set_grad_enabled(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "412a54c9-d0bf-45be-9f71-ae23211e144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高斯噪声变换\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=0.05):\n",
    "        self.mean, self.std = mean, std\n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn_like(tensor)*self.std + self.mean\n",
    "\n",
    "# 训练增强（旋转±15°、亮度抖动、噪声）+ 与 ResNet 匹配的归一化\n",
    "train_tf = T.Compose([\n",
    "    T.Resize((224,224)),\n",
    "    T.RandomApply([T.RandomRotation(degrees=15)], p=0.8),\n",
    "    T.ColorJitter(brightness=0.2),          # ±20% 亮度\n",
    "    T.ToTensor(),\n",
    "    AddGaussianNoise(std=0.03),             # 适中噪声\n",
    "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "# 测试/验证不做增强（与预训练分布一致）\n",
    "test_tf = preprocess_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4681cdc-4bd1-48a1-a8c0-07133bd8bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 过滤坏图（可选，建议保留）\n",
    "def is_valid_image(p: str) -> bool:\n",
    "    try:\n",
    "        with Image.open(p) as im:\n",
    "            im.verify()\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# 构建“干净”的全集（先用 test_tf；训练时再用同索引替换 transform）\n",
    "root = \"Animals_with_Attributes2/JPEGImages\"\n",
    "whole_ds = ImageFolder(root=root, transform=test_tf, is_valid_file=is_valid_image)\n",
    "class_to_idx = whole_ds.class_to_idx  # {'antelope':0,...}\n",
    "\n",
    "# 每个样本 (path, label)\n",
    "samples = whole_ds.samples             # list[(path,label)]\n",
    "labels  = [lbl for _, lbl in samples]\n",
    "num_classes = len(class_to_idx)        # 50\n",
    "\n",
    "# —— 类级 10 折（按类ID均分，确保 Zero-Shot）——\n",
    "all_classes = list(range(num_classes))\n",
    "random.Random(42).shuffle(all_classes)\n",
    "fold_size = math.ceil(num_classes/10)\n",
    "fold_classes = [all_classes[i*fold_size:(i+1)*fold_size] for i in range(10)]\n",
    "\n",
    "def idx_of_classes(lbls, cls_set):\n",
    "    s = set(cls_set); return [i for i, y in enumerate(lbls) if y in s]\n",
    "\n",
    "def make_dataloaders_for_fold(k, batch=64, nw=4):\n",
    "    unseen_cls = fold_classes[k]                         # 本折的 unseen 类\n",
    "    seen_cls   = [c for c in all_classes if c not in unseen_cls]\n",
    "\n",
    "    tr_idx = idx_of_classes(labels, seen_cls)\n",
    "    te_idx = idx_of_classes(labels, unseen_cls)\n",
    "\n",
    "    # 训练子集用“训练增强” transform\n",
    "    train_subset = Subset(ImageFolder(root=root, transform=train_tf, is_valid_file=is_valid_image), tr_idx)\n",
    "    # 测试子集用“评估” transform\n",
    "    test_subset  = Subset(whole_ds, te_idx)  # whole_ds 已是 test_tf\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch, shuffle=True,\n",
    "                              num_workers=nw, pin_memory=True, persistent_workers=(nw>0))\n",
    "    test_loader  = DataLoader(test_subset,  batch_size=batch, shuffle=False,\n",
    "                              num_workers=nw, pin_memory=True, persistent_workers=(nw>0))\n",
    "    return train_loader, test_loader, torch.tensor(seen_cls), torch.tensor(unseen_cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09818a8b-4189-4e4c-9e72-97a3e816d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def read_title_and_desc_clean(txt_path):\n",
    "    \"\"\"读取 AwA2 licenses txt 文件中的 TITLE 和 DESCRIPTION 字段（去掉符号框线）\"\"\"\n",
    "    title, desc = \"\", \"\"\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    clean = lambda s: re.sub(r'[\\+\\-\\|\\_]+', '', s).strip()  # 删除 + - | _\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if \"TITLE\" in line.upper() and i + 1 < len(lines):\n",
    "            title = clean(lines[i + 1])\n",
    "        if \"DESCRIPTION\" in line.upper():\n",
    "            desc_lines = []\n",
    "            for j in range(i + 1, len(lines)):\n",
    "                if any(k in lines[j].upper() for k in [\"TITLE\", \"INFO\", \"TAGS\", \"PHOTOGRAPHER\", \"LICENSE\"]):\n",
    "                    break\n",
    "                desc_lines.append(clean(lines[j]))\n",
    "            desc = \" \".join(desc_lines).strip()\n",
    "            break\n",
    "    return title, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fadeb3b3-0c56-4963-8a74-4b45443623e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: \n",
      "DESCRIPTION: You are free to use this photo  (including commercial use) under attribution to the author. If being used online please add a link to <a href=\"http://ujora.de\" rel=\"nofollow\">ujora.de</a> Dieses Foto  ...\n"
     ]
    }
   ],
   "source": [
    "#check\n",
    "txt_path = \"Animals_with_Attributes2/licenses/antelope/antelope_10021.txt\"\n",
    "title, desc = read_title_and_desc_clean(txt_path)\n",
    "print(\"TITLE:\", title)\n",
    "print(\"DESCRIPTION:\", desc[:200], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "413f2e8d-0924-4332-9841-8d6d43fa988f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "行数(应为50): 50\n",
      "   label       class  n_txt\n",
      "0    0.0    antelope   1046\n",
      "1    1.0         bat    178\n",
      "2    2.0      beaver    147\n",
      "3    3.0  blue+whale    174\n",
      "4    4.0      bobcat    627\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "IMG_ROOT = \"Animals_with_Attributes2/JPEGImages\"\n",
    "TXT_ROOT = \"Animals_with_Attributes2/licenses\"\n",
    "\n",
    "# 用于与标签对齐（确保顺序和 y_test 的 0..49 一致）\n",
    "class_to_idx = datasets.ImageFolder(IMG_ROOT).class_to_idx  # {'antelope':0, ...}\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "# 读取并清洗单个 txt 的 TITLE 和 DESCRIPTION（去掉框线/下划线/HTML标签）\n",
    "def read_title_and_desc_clean(p):\n",
    "    title, desc = \"\", \"\"\n",
    "    clean = lambda s: re.sub(r'[\\+\\-\\|\\_]+', '', s).strip()\n",
    "    with open(p, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        U = line.upper()\n",
    "        if \"TITLE\" in U and i + 1 < len(lines):\n",
    "            title = clean(lines[i + 1])\n",
    "        if \"DESCRIPTION\" in U:\n",
    "            buf = []\n",
    "            for j in range(i + 1, len(lines)):\n",
    "                if any(k in lines[j].upper() for k in [\"TITLE\",\"INFO\",\"TAGS\",\"PHOTOGRAPHER\",\"LICENSE\"]):\n",
    "                    break\n",
    "                buf.append(clean(lines[j]))\n",
    "            desc = \" \".join(buf).strip()\n",
    "            break\n",
    "    # 去掉 HTML 标签\n",
    "    title = re.sub(r\"<.*?>\", \"\", title)\n",
    "    desc  = re.sub(r\"<.*?>\", \"\", desc)\n",
    "    return title, desc\n",
    "\n",
    "# 按类别汇总：每个子文件夹 -> 拼接所有 txt 的 title+desc\n",
    "rows = []\n",
    "for cls in sorted(os.listdir(TXT_ROOT)):\n",
    "    cls_dir = os.path.join(TXT_ROOT, cls)\n",
    "    if not os.path.isdir(cls_dir):\n",
    "        continue\n",
    "    pieces = []\n",
    "    for fname in sorted(os.listdir(cls_dir)):\n",
    "        if fname.endswith(\".txt\"):\n",
    "            t, d = read_title_and_desc_clean(os.path.join(cls_dir, fname))\n",
    "            text = \" \".join([t, d]).strip()\n",
    "            if text:\n",
    "                pieces.append(text)\n",
    "    merged = \" \".join(pieces)              # 该类别的整合文本\n",
    "    rows.append({\"class\": cls, \"text\": merged, \"n_txt\": len(pieces)})\n",
    "\n",
    "# 变成 DataFrame，并按 label 顺序(0..49) 排好，方便与 y_test 对齐\n",
    "df = pd.DataFrame(rows)\n",
    "df[\"label\"] = df[\"class\"].map(class_to_idx)\n",
    "df = df.sort_values(\"label\").reset_index(drop=True)\n",
    "df = df.iloc[:-1].reset_index(drop=True)\n",
    "print(\"行数(应为50):\", len(df))\n",
    "print(df[[\"label\",\"class\",\"n_txt\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e7d3877-2b61-4784-a8de-cf8ddb85955d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>n_txt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>antelope</td>\n",
       "      <td>\\And God said, Let the earth bring forth the l...</td>\n",
       "      <td>1046</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bat</td>\n",
       "      <td>Found below the power lines at Hamilton Beach....</td>\n",
       "      <td>178</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beaver</td>\n",
       "      <td>the local beavers on Christmas day 2007 (no de...</td>\n",
       "      <td>147</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blue+whale</td>\n",
       "      <td>(no description) Free Fall breaching. (no desc...</td>\n",
       "      <td>174</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bobcat</td>\n",
       "      <td>One of the cubs walking in the enclosure, unde...</td>\n",
       "      <td>627</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        class                                               text  n_txt  label\n",
       "0    antelope  \\And God said, Let the earth bring forth the l...   1046    0.0\n",
       "1         bat  Found below the power lines at Hamilton Beach....    178    1.0\n",
       "2      beaver  the local beavers on Christmas day 2007 (no de...    147    2.0\n",
       "3  blue+whale  (no description) Free Fall breaching. (no desc...    174    3.0\n",
       "4      bobcat  One of the cubs walking in the enclosure, unde...    627    4.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9325b695-6b56-43e2-a03b-201d790483cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape: (50, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 你已经有 df（50行），每行是一个类别的 text\n",
    "texts = df[\"text\"].fillna(\"\").tolist()\n",
    "\n",
    "# 1) 定义 TF-IDF 模型\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=1000,       # 取前1000个高频特征，可调\n",
    "    stop_words=\"english\",    # 去除英文停用词\n",
    "    lowercase=True           # 全部转小写\n",
    ")\n",
    "\n",
    "# 2) 拟合并变换\n",
    "X_tfidf = tfidf.fit_transform(texts)      # shape (50, vocab_size)\n",
    "print(\"TF-IDF shape:\", X_tfidf.shape)\n",
    "\n",
    "# 3) 转成 torch.Tensor，方便和你的 test_whole 拼接\n",
    "X_tfidf_tensor = torch.tensor(X_tfidf.toarray(), dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5eeb5ae5-d256-44fa-9e80-b1b713059422",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = X_tfidf_tensor.float()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9f9f058-37eb-4a18-a5f8-a76f4e769f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "V = S.shape[1]\n",
    "\n",
    "def extract_feats(dl):\n",
    "    feats, lbls = [], []\n",
    "    for imgs, y in dl:\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        f = resnet(imgs).detach().cpu()      # [B, 2048]\n",
    "        feats.append(f); lbls.append(y)\n",
    "    return torch.cat(feats,0), torch.cat(lbls,0)\n",
    "\n",
    "# —— 示例：跑一折，得到训练/测试特征，并与语义对齐 ——\n",
    "k = 0  # 第 1 折\n",
    "train_loader, test_loader, seen_cls, unseen_cls = make_dataloaders_for_fold(k)\n",
    "\n",
    "X_tr, y_tr = extract_feats(train_loader)     # [Ntr, 2048], [Ntr]\n",
    "X_te, y_te = extract_feats(test_loader)      # [Nte, 2048], [Nte]\n",
    "\n",
    "# 训练目标：样本所属类的语义向量\n",
    "Y_tr = S[y_tr]                                # [Ntr, V]\n",
    "\n",
    "# ——（可选）拼接通道：把图像特征与其类语义拼接，做一些对照基线 —— \n",
    "# 这在 ZSL 训练阶段常用于判别器/回归器的额外输入；真正测试时仍只用图像→语义映射。\n",
    "X_tr_concat = torch.cat([X_tr, Y_tr], dim=1)  # [Ntr, 2048+V]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a89d78b0-6121-42c6-b3ab-e6df4ba378ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Seen class number=45, Unseen class number=5\n",
      "  training samples=33048, test samples=4258\n",
      "  Seen class index: [45, 26, 9, 29, 16, 31, 21, 12, 3, 39, 38, 10, 24, 35, 0, 43, 18, 33, 48, 41, 30, 28, 20, 22, 42, 46, 36, 32, 44, 13, 49, 47, 2, 27, 37, 5, 34, 6, 8, 14, 15, 17, 1, 7, 40]\n",
      "  Unseen class index: [25, 23, 19, 11, 4]\n",
      "------------------------------------------------------------\n",
      "Fold 2:\n",
      "  Seen class number=45, Unseen class number=5\n",
      "  training samples=33013, test samples=4293\n",
      "  Seen class index: [25, 23, 19, 11, 4, 31, 21, 12, 3, 39, 38, 10, 24, 35, 0, 43, 18, 33, 48, 41, 30, 28, 20, 22, 42, 46, 36, 32, 44, 13, 49, 47, 2, 27, 37, 5, 34, 6, 8, 14, 15, 17, 1, 7, 40]\n",
      "  Unseen class index: [45, 26, 9, 29, 16]\n",
      "------------------------------------------------------------\n",
      "Fold 3:\n",
      "  Seen class number=45, Unseen class number=5\n",
      "  training samples=33783, test samples=3523\n",
      "  Seen class index: [25, 23, 19, 11, 4, 45, 26, 9, 29, 16, 38, 10, 24, 35, 0, 43, 18, 33, 48, 41, 30, 28, 20, 22, 42, 46, 36, 32, 44, 13, 49, 47, 2, 27, 37, 5, 34, 6, 8, 14, 15, 17, 1, 7, 40]\n",
      "  Unseen class index: [31, 21, 12, 3, 39]\n",
      "------------------------------------------------------------\n",
      "Fold 4:\n",
      "  Seen class number=45, Unseen class number=5\n",
      "  training samples=33635, test samples=3671\n",
      "  Seen class index: [25, 23, 19, 11, 4, 45, 26, 9, 29, 16, 31, 21, 12, 3, 39, 43, 18, 33, 48, 41, 30, 28, 20, 22, 42, 46, 36, 32, 44, 13, 49, 47, 2, 27, 37, 5, 34, 6, 8, 14, 15, 17, 1, 7, 40]\n",
      "  Unseen class index: [38, 10, 24, 35, 0]\n",
      "------------------------------------------------------------\n",
      "Fold 5:\n",
      "  Seen class number=45, Unseen class number=5\n",
      "  training samples=34339, test samples=2967\n",
      "  Seen class index: [25, 23, 19, 11, 4, 45, 26, 9, 29, 16, 31, 21, 12, 3, 39, 38, 10, 24, 35, 0, 30, 28, 20, 22, 42, 46, 36, 32, 44, 13, 49, 47, 2, 27, 37, 5, 34, 6, 8, 14, 15, 17, 1, 7, 40]\n",
      "  Unseen class index: [43, 18, 33, 48, 41]\n",
      "------------------------------------------------------------\n",
      "Fold 6:\n",
      "  Seen class number=45, Unseen class number=5\n",
      "  training samples=33258, test samples=4048\n",
      "  Seen class index: [25, 23, 19, 11, 4, 45, 26, 9, 29, 16, 31, 21, 12, 3, 39, 38, 10, 24, 35, 0, 43, 18, 33, 48, 41, 46, 36, 32, 44, 13, 49, 47, 2, 27, 37, 5, 34, 6, 8, 14, 15, 17, 1, 7, 40]\n",
      "  Unseen class index: [30, 28, 20, 22, 42]\n",
      "------------------------------------------------------------\n",
      "Fold 7:\n",
      "  Seen class number=45, Unseen class number=5\n",
      "  training samples=33593, test samples=3713\n",
      "  Seen class index: [25, 23, 19, 11, 4, 45, 26, 9, 29, 16, 31, 21, 12, 3, 39, 38, 10, 24, 35, 0, 43, 18, 33, 48, 41, 30, 28, 20, 22, 42, 49, 47, 2, 27, 37, 5, 34, 6, 8, 14, 15, 17, 1, 7, 40]\n",
      "  Unseen class index: [46, 36, 32, 44, 13]\n",
      "------------------------------------------------------------\n",
      "Fold 8:\n",
      "  Seen class number=45, Unseen class number=5\n",
      "  training samples=35261, test samples=2045\n",
      "  Seen class index: [25, 23, 19, 11, 4, 45, 26, 9, 29, 16, 31, 21, 12, 3, 39, 38, 10, 24, 35, 0, 43, 18, 33, 48, 41, 30, 28, 20, 22, 42, 46, 36, 32, 44, 13, 5, 34, 6, 8, 14, 15, 17, 1, 7, 40]\n",
      "  Unseen class index: [49, 47, 2, 27, 37]\n",
      "------------------------------------------------------------\n",
      "Fold 9:\n",
      "  Seen class number=45, Unseen class number=5\n",
      "  training samples=33284, test samples=4022\n",
      "  Seen class index: [25, 23, 19, 11, 4, 45, 26, 9, 29, 16, 31, 21, 12, 3, 39, 38, 10, 24, 35, 0, 43, 18, 33, 48, 41, 30, 28, 20, 22, 42, 46, 36, 32, 44, 13, 49, 47, 2, 27, 37, 15, 17, 1, 7, 40]\n",
      "  Unseen class index: [5, 34, 6, 8, 14]\n",
      "------------------------------------------------------------\n",
      "Fold 10:\n",
      "  Seen class number=45, Unseen class number=5\n",
      "  training samples=32540, test samples=4766\n",
      "  Seen class index: [25, 23, 19, 11, 4, 45, 26, 9, 29, 16, 31, 21, 12, 3, 39, 38, 10, 24, 35, 0, 43, 18, 33, 48, 41, 30, 28, 20, 22, 42, 46, 36, 32, 44, 13, 49, 47, 2, 27, 37, 5, 34, 6, 8, 14]\n",
      "  Unseen class index: [15, 17, 1, 7, 40]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for k in range(10):\n",
    "    train_loader, test_loader, seen_cls, unseen_cls = make_dataloaders_for_fold(k)\n",
    "    print(f\"Fold {k+1}:\")\n",
    "    print(f\"  Seen class number={len(seen_cls)}, Unseen class number={len(unseen_cls)}\")\n",
    "    print(f\"  training samples={len(train_loader.dataset)}, test samples={len(test_loader.dataset)}\")\n",
    "    print(\"  Seen class index:\", seen_cls.tolist())\n",
    "    print(\"  Unseen class index:\", unseen_cls.tolist())\n",
    "    print(\"-\"*60)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a7df2d9-416c-40a7-8208-7ee92aff9cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f15832f3-d9aa-4f11-93c2-bacb1dd87a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random, torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "def set_seed(s=42):\n",
    "    random.seed(s); torch.manual_seed(s); \n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(s)\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_feats(dl, feature_net):\n",
    "    feats, lbls = [], []\n",
    "    for imgs, y in dl:\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        f = feature_net(imgs).detach().cpu()     # [B, 2048]\n",
    "        feats.append(f); lbls.append(y)\n",
    "    return torch.cat(feats,0), torch.cat(lbls,0)\n",
    "\n",
    "@torch.no_grad()\n",
    "def zsl_acc(pred_sem, S_cand, true_lbls, cand_lbl_ids):\n",
    "    pred_sem = F.normalize(pred_sem, dim=1)\n",
    "    S_cand   = F.normalize(S_cand, dim=1)\n",
    "    sims = pred_sem @ S_cand.T\n",
    "    pred_idx = sims.argmax(dim=1)\n",
    "    pred_lbl = cand_lbl_ids[pred_idx]\n",
    "    return (pred_lbl == true_lbls).float().mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c22fc5c-add0-47a0-abb4-828db32c30d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_classes_k3(seen_classes, seed=0):\n",
    "    \"\"\"把 seen 类平均分成 3 份，返回 [C1, C2, C3]（每份是类ID列表）\"\"\"\n",
    "    clz = list(map(int, seen_classes))\n",
    "    random.Random(seed).shuffle(clz)\n",
    "    s = math.ceil(len(clz)/3)\n",
    "    return [clz[:s], clz[s:2*s], clz[2*s:]]\n",
    "\n",
    "def idx_of_classes(y_vec, cls_set):\n",
    "    \"\"\"给定样本标签向量 y 和类集合，返回属于这些类的样本索引列表\"\"\"\n",
    "    ss = set(map(int, cls_set))\n",
    "    y_list = y_vec if isinstance(y_vec, list) else y_vec.tolist()\n",
    "    return [i for i, yy in enumerate(y_list) if int(yy) in ss]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0949bf8d-ec80-4be4-abbd-b3874cd2e272",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hid, out_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid, out_dim),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "def train_epoch(model, X, Y, opt, batch_size=512):\n",
    "    model.train(); torch.set_grad_enabled(True)\n",
    "    N = X.shape[0]\n",
    "    perm = torch.randperm(N)\n",
    "    loss_sum = 0.0\n",
    "    for i in range(0, N, batch_size):\n",
    "        idx = perm[i:i+batch_size]\n",
    "        xb, yb = X[idx], Y[idx]\n",
    "        pred = model(xb)\n",
    "        loss = F.mse_loss(pred, yb)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        loss_sum += loss.item() * xb.size(0)\n",
    "    torch.set_grad_enabled(False)\n",
    "    return loss_sum / N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75aa55c6-40ed-4d70-a4e4-666cb46d502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_mlp_inner3(Xtr, ytr, S, seen_cls, grid, epochs=30, wd=0.0, seed=0):\n",
    "    \"\"\"\n",
    "    Xtr: [Ntr, 2048] 训练特征（seen 样本）\n",
    "    ytr: [Ntr]       训练标签（全局类ID）\n",
    "    S:   [50, V]     类语义矩阵\n",
    "    seen_cls: [Ns]   本折的 seen 类ID\n",
    "    grid: list of dicts: [{'hid':..., 'lr':...}, ...]\n",
    "    \"\"\"\n",
    "    parts = split_classes_k3(seen_cls, seed=seed)   # [C1, C2, C3]\n",
    "    best_cfg, best_score, best_key = None, -1.0, None\n",
    "\n",
    "    # 为了“中间值更常被选中”的要求，准备一个tie-break键\n",
    "    hid_order = [512,1024,2048]; lr_order = [1e-2,1e-3,1e-4]\n",
    "\n",
    "    for cfg in grid:\n",
    "        scores = []\n",
    "        for k in range(3):\n",
    "            val_cls = parts[k]\n",
    "            tr_cls  = parts[(k+1)%3] + parts[(k+2)%3]\n",
    "\n",
    "            tr_idx = idx_of_classes(ytr, tr_cls)\n",
    "            va_idx = idx_of_classes(ytr, val_cls)\n",
    "\n",
    "            X_tr, Y_tr = Xtr[tr_idx], S[ytr[tr_idx]]\n",
    "            X_va, y_va = Xtr[va_idx], ytr[va_idx]\n",
    "\n",
    "            model = MLP(2048, cfg['hid'], S.shape[1]).to('cpu')\n",
    "            opt   = torch.optim.Adam(model.parameters(), lr=cfg['lr'], weight_decay=wd)\n",
    "\n",
    "            for ep in range(epochs):\n",
    "                train_epoch(model, X_tr, Y_tr, opt)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred_sem = model(X_va)\n",
    "                acc = zsl_acc(pred_sem, S[val_cls], y_va, torch.tensor(val_cls))\n",
    "            scores.append(acc)\n",
    "\n",
    "        mean_acc = sum(scores)/len(scores)\n",
    "        # tie-break：靠近中档优先\n",
    "        key = (mean_acc, -abs(hid_order.index(cfg['hid'])-1), -abs(lr_order.index(cfg['lr'])-1))\n",
    "        if (mean_acc > best_score) or (abs(mean_acc-best_score)<1e-12 and (best_key is None or key > best_key)):\n",
    "            best_cfg, best_score, best_key = cfg, mean_acc, key\n",
    "\n",
    "    return best_cfg, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9384475a-9905-48e5-bef8-eb8c497a50c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_once_get_best_cfg(resnet, S, *, seed=42, inner_epochs=30, wd=0.0):\n",
    "    \"\"\"\n",
    "    只在一次 k=3 内层上确定 best_cfg，然后全程复用。\n",
    "    用第 0 折的 seen 类做伪 ZSL（split_classes_k3 + tune_mlp_inner3）。\n",
    "    \"\"\"\n",
    "    set_seed(seed)\n",
    "    k_tune = 0\n",
    "    train_loader, _, seen_cls, _ = make_dataloaders_for_fold(k_tune)\n",
    "    Xtr, ytr = extract_feats(train_loader, resnet)   # 你已有的接口签名\n",
    "\n",
    "    grid = [{'hid': h, 'lr': lr}\n",
    "            for h in [512, 1024, 2048]\n",
    "            for lr in [1e-2, 1e-3, 1e-4]]\n",
    "\n",
    "    # ⏳ 这里会训练（tune_mlp_inner3 里会跑 3 次 * len(grid) 轮）\n",
    "    best_cfg, inner_score = tune_mlp_inner3(Xtr, ytr, S, seen_cls, grid,\n",
    "                                            epochs=inner_epochs, wd=wd, seed=seed)\n",
    "    print(f\"[TuneOnce@fold0] best_cfg={best_cfg} | inner-3fold acc={inner_score:.4f}\")\n",
    "    return best_cfg, inner_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "085e146f-9d2b-4764-a9c7-e47d1b2744c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_fold_with_cfg(k, resnet, S, best_cfg, *, epochs_final=40, seed=42):\n",
    "    \"\"\"\n",
    "    使用已经确定的 best_cfg：\n",
    "    - 训练：在本折全部 seen 训练样本上用 MLP 学图像->语义（⏳）\n",
    "    - 测试：只在本折 unseen 类里做 ZSL 评估\n",
    "    \"\"\"\n",
    "    set_seed(seed)\n",
    "\n",
    "    # 1) 本折数据\n",
    "    train_loader, test_loader, seen_cls, unseen_cls = make_dataloaders_for_fold(k)\n",
    "\n",
    "    # 2) 提特征（复用你的函数）\n",
    "    X_tr, y_tr = extract_feats(train_loader, resnet)  # [Ntr, 2048], [Ntr]\n",
    "    X_te, y_te = extract_feats(test_loader,  resnet)  # [Nte, 2048], [Nte]\n",
    "\n",
    "    # 3) 训练 MLP（⏳）\n",
    "    torch.set_grad_enabled(True)\n",
    "    model = MLP(2048, best_cfg['hid'], S.shape[1]).to('cpu')\n",
    "    opt   = torch.optim.Adam(model.parameters(), lr=best_cfg['lr'])\n",
    "    Y_tr  = S[y_tr]   # 训练目标：类语义\n",
    "    for _ in range(epochs_final):\n",
    "        train_epoch(model, X_tr, Y_tr, opt)\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    # 4) 外层真实 ZSL 测试（只在 unseen 候选里做语义最近邻）\n",
    "    with torch.no_grad():\n",
    "        pred_sem = model(X_te)\n",
    "        acc = zsl_acc(pred_sem, S[unseen_cls], y_te, torch.tensor(unseen_cls))\n",
    "    return acc, best_cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "702c0fa6-70b0-4395-be64-052f4ba223b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TuneOnce@fold0] best_cfg={'hid': 512, 'lr': 0.001} | inner-3fold acc=0.1096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1333/2624383076.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  acc = zsl_acc(pred_sem, S[unseen_cls], y_te, torch.tensor(unseen_cls))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: acc=0.4605\n",
      "Fold 2: acc=0.4990\n",
      "Fold 3: acc=0.2552\n",
      "Fold 4: acc=0.2939\n",
      "Fold 5: acc=0.2946\n",
      "Fold 6: acc=0.4452\n",
      "Fold 7: acc=0.3520\n",
      "Fold 8: acc=0.1516\n",
      "Fold 9: acc=0.3123\n",
      "Fold 10: acc=0.3034\n",
      "\n",
      "======== Summary ========\n",
      "Per-fold acc : ['0.4605', '0.4990', '0.2552', '0.2939', '0.2946', '0.4452', '0.3520', '0.1516', '0.3123', '0.3034']\n",
      "Mean acc     : 0.3368\n",
      "Std (10fold) : 0.1053\n",
      "95% CI       : ±0.0653\n",
      "Fixed cfg    : {'hid': 512, 'lr': 0.001}, (inner-3fold=0.1096)\n"
     ]
    }
   ],
   "source": [
    "# 固定随机种子\n",
    "set_seed(42)\n",
    "\n",
    "# 第一步：只跑一次 k=3 内层调参\n",
    "best_cfg, inner_score = tune_once_get_best_cfg(resnet, S, seed=42, inner_epochs=30, wd=0.0)\n",
    "\n",
    "# 第二步：用固定 best_cfg 跑 10 折（每折仅训练 MLP + 测试）\n",
    "accs, cfgs = [], []\n",
    "for k in range(10):\n",
    "    acc, _ = run_one_fold_with_cfg(k, resnet, S, best_cfg, epochs_final=40, seed=42+k)\n",
    "    accs.append(acc)\n",
    "    cfgs.append(best_cfg)\n",
    "    print(f\"Fold {k+1}: acc={acc:.4f}\")\n",
    "\n",
    "# 汇总\n",
    "mean_acc = sum(accs) / len(accs)\n",
    "import math\n",
    "std = math.sqrt(sum((a - mean_acc)**2 for a in accs) / (len(accs) - 1))\n",
    "ci95 = 1.96 * std / math.sqrt(len(accs))\n",
    "\n",
    "print(\"\\n======== Summary ========\")\n",
    "print(\"Per-fold acc :\", [f\"{a:.4f}\" for a in accs])\n",
    "print(f\"Mean acc     : {mean_acc:.4f}\")\n",
    "print(f\"Std (10fold) : {std:.4f}\")\n",
    "print(f\"95% CI       : ±{ci95:.4f}\")\n",
    "print(f\"Fixed cfg    : {best_cfg}, (inner-3fold={inner_score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94940a1c-fb39-4a07-a08a-fed8712bb39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== f-CLSWGAN: 模型与训练 =====\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np, random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class _FeatDS(Dataset):\n",
    "    def __init__(self, X: torch.Tensor, y: torch.Tensor):\n",
    "        self.X = X.float().contiguous()\n",
    "        self.y = y.long().contiguous()\n",
    "    def __len__(self): return self.y.numel()\n",
    "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
    "\n",
    "class G(nn.Module):  # 生成器\n",
    "    def __init__(self, z_dim, a_dim, x_dim, hidden=2048):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(z_dim + a_dim, hidden), nn.LeakyReLU(0.2, True),\n",
    "            nn.Linear(hidden, hidden),         nn.LeakyReLU(0.2, True),\n",
    "            nn.Linear(hidden, x_dim),\n",
    "        )\n",
    "    def forward(self, z, a): return self.net(torch.cat([z, a], dim=1))\n",
    "\n",
    "class D(nn.Module):  # 判别器\n",
    "    def __init__(self, x_dim, a_dim, hidden=2048):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(x_dim + a_dim, hidden), nn.LeakyReLU(0.2, True),\n",
    "            nn.Linear(hidden, hidden),         nn.LeakyReLU(0.2, True),\n",
    "            nn.Linear(hidden, 1),\n",
    "        )\n",
    "    def forward(self, x, a): return self.net(torch.cat([x, a], dim=1))\n",
    "\n",
    "def _grad_penalty(Dmod, real_x, fake_x, a, gp_lambda=10.0):\n",
    "    b = real_x.size(0)\n",
    "    eps = torch.rand(b, 1, device=real_x.device).expand_as(real_x)\n",
    "    inter = (eps*real_x + (1-eps)*fake_x).requires_grad_(True)\n",
    "    d_inter = Dmod(inter, a)\n",
    "    grads = torch.autograd.grad(d_inter, inter, torch.ones_like(d_inter),\n",
    "                                create_graph=True, retain_graph=True)[0]\n",
    "    return gp_lambda * ((grads.view(b, -1).norm(2, dim=1) - 1)**2).mean()\n",
    "\n",
    "def train_wgan_seen(  # ⏳ 训练 GAN（只用 seen 样本）\n",
    "    X_seen, y_seen_sid, A_seen, *,\n",
    "    z_dim=100, g_hidden=2048, d_hidden=2048,\n",
    "    lr=1e-4, n_epochs=40, batch_size=256, n_critic=5, gp_lambda=10.0, seed=42\n",
    "):\n",
    "    random.seed(seed); torch.manual_seed(seed); \n",
    "    x_dim, a_dim = X_seen.size(1), A_seen.size(1)\n",
    "    Gmod, Dmod = G(z_dim, a_dim, x_dim, g_hidden).to(device), D(x_dim, a_dim, d_hidden).to(device)\n",
    "    optG = torch.optim.Adam(Gmod.parameters(), lr=lr, betas=(0.5, 0.9))\n",
    "    optD = torch.optim.Adam(Dmod.parameters(), lr=lr, betas=(0.5, 0.9))\n",
    "    A_seen = A_seen.float().to(device)\n",
    "    dl = DataLoader(_FeatDS(X_seen, y_seen_sid), batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    for _ in range(n_epochs):\n",
    "        for xb, yb_sid in dl:\n",
    "            xb, yb_sid = xb.to(device), yb_sid.to(device)\n",
    "            B = xb.size(0)\n",
    "            for _ in range(n_critic):\n",
    "                a = A_seen[yb_sid]; z = torch.randn(B, z_dim, device=device)\n",
    "                x_fake = Gmod(z, a).detach()\n",
    "                lossD = -(Dmod(xb, a).mean() - Dmod(x_fake, a).mean()) + _grad_penalty(Dmod, xb, x_fake, a, gp_lambda)\n",
    "                optD.zero_grad(); lossD.backward(); optD.step()\n",
    "            a = A_seen[yb_sid]; z = torch.randn(B, z_dim, device=device)\n",
    "            lossG = - Dmod(Gmod(z, a), a).mean()\n",
    "            optG.zero_grad(); lossG.backward(); optG.step()\n",
    "    return Gmod\n",
    "\n",
    "def synth_unseen(Gmod, A_unseen, n_per_class=300, z_dim=100):\n",
    "    Gmod.eval()\n",
    "    with torch.no_grad():\n",
    "        K = A_unseen.size(0)\n",
    "        z = torch.randn(K*n_per_class, z_dim, device=device)\n",
    "        a = A_unseen.float().to(device).repeat_interleave(n_per_class, 0)\n",
    "        Xsyn = Gmod(z, a).cpu()\n",
    "    return Xsyn  # [K*n, x_dim]\n",
    "\n",
    "# 轻量线性分类器（在合成特征上训练）\n",
    "class LinearSoftmax(nn.Module):\n",
    "    def __init__(self, in_dim, n_cls): super().__init__(); self.fc = nn.Linear(in_dim, n_cls)\n",
    "    def forward(self, x): return self.fc(x)\n",
    "\n",
    "def train_clf(  # ⏳ 训练分类器\n",
    "    X, y, n_cls, *, epochs=30, lr=1e-3, wd=1e-4, bs=256, seed=42\n",
    "):\n",
    "    random.seed(seed); torch.manual_seed(seed)\n",
    "    clf = LinearSoftmax(X.size(1), n_cls).to(device)\n",
    "    opt = torch.optim.Adam(clf.parameters(), lr=lr, weight_decay=wd)\n",
    "    dl = DataLoader(_FeatDS(X, y), batch_size=bs, shuffle=True)\n",
    "    for _ in range(epochs):\n",
    "        for xb, yb in dl:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            loss = F.cross_entropy(clf(xb), yb)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "    return clf\n",
    "\n",
    "def acc_of(clf, X, y):\n",
    "    clf.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = clf(X.to(device)).argmax(1).cpu()\n",
    "    return float((pred == y).float().mean().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c953f33-42ff-4bfd-9dee-45b2d9f6b1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -q install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab0f2861-8903-4aa4-8eb6-1b9762b1983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === f-CLSWGAN ① 依赖与小工具（无需等待） ===\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np, random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def set_seed_all(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); \n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "class _FeatDS(Dataset):\n",
    "    def __init__(self, X: torch.Tensor, y: torch.Tensor):\n",
    "        self.X = X.float().contiguous()\n",
    "        self.y = y.long().contiguous()\n",
    "    def __len__(self): return self.y.numel()\n",
    "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
    "\n",
    "def acc_of(model: nn.Module, X: torch.Tensor, y: torch.Tensor) -> float:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(X.to(device)).argmax(1).cpu()\n",
    "    return float((pred == y).float().mean().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "db9e64c4-db72-4ad9-ad09-f6d6fcf83dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class G(nn.Module):  # 生成器\n",
    "    def __init__(self, z_dim, a_dim, x_dim, hidden=2048):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(z_dim + a_dim, hidden),\n",
    "            nn.LeakyReLU(0.2, inplace=False),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.LeakyReLU(0.2, inplace=False),\n",
    "            nn.Linear(hidden, x_dim),\n",
    "        )\n",
    "    def forward(self, z, a):\n",
    "        # 保障 dtype/device 一致\n",
    "        if a.dtype != z.dtype: a = a.to(z.dtype)\n",
    "        if a.device != z.device: a = a.to(z.device)\n",
    "        return self.net(torch.cat([z, a], dim=1))\n",
    "\n",
    "class D(nn.Module):  # 判别器\n",
    "    def __init__(self, x_dim, a_dim, hidden=2048):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(x_dim + a_dim, hidden),\n",
    "            nn.LeakyReLU(0.2, inplace=False),   # ⚠️ 关闭 inplace\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.LeakyReLU(0.2, inplace=False),   # ⚠️ 关闭 inplace\n",
    "            nn.Linear(hidden, 1),\n",
    "        )\n",
    "    def forward(self, x, a):\n",
    "        if a.dtype != x.dtype: a = a.to(x.dtype)\n",
    "        if a.device != x.device: a = a.to(x.device)\n",
    "        out = self.net(torch.cat([x, a], dim=1))\n",
    "        return out.view(out.size(0))            # 直接返回 (B,)\n",
    "\n",
    "def grad_penalty(Dmod, real_x, fake_x, a, gp_lambda):\n",
    "    B = real_x.size(0)\n",
    "    eps = torch.rand(B, 1, device=real_x.device)       # 向量特征 -> (B,1)\n",
    "\n",
    "    # 只对 inter 打开梯度，real/fake 可 detach 以免传回 G\n",
    "    inter = (eps * real_x.detach() + (1 - eps) * fake_x.detach()).requires_grad_(True)\n",
    "\n",
    "    with torch.enable_grad():  # 覆盖外层任何 no_grad\n",
    "        d_inter = Dmod(inter, a)                         # 形状 (B,)\n",
    "        grad_outputs = torch.ones_like(d_inter)\n",
    "        grads = torch.autograd.grad(\n",
    "            outputs=d_inter,\n",
    "            inputs=inter,\n",
    "            grad_outputs=grad_outputs,\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True\n",
    "        )[0]                                            # (B, x_dim)\n",
    "\n",
    "    gp = gp_lambda * ((grads.view(B, -1).norm(2, dim=1) - 1.0) ** 2).mean()\n",
    "    return gp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b820f06a-0807-4231-9e4c-a1c84fd62346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_wgan_seen(  # 只用 seen 样本训练 WGAN-GP（稳定版）\n",
    "    X_seen, y_seen_sid, A_seen, *,\n",
    "    z_dim=100, g_hidden=2048, d_hidden=2048,\n",
    "    lr=1e-4, n_epochs=40, batch_size=256,\n",
    "    n_critic=5, gp_lambda=10.0, seed=42,\n",
    "    desc=\"GAN(seen)\"\n",
    "):\n",
    "    set_seed_all(seed)\n",
    "    x_dim, a_dim = X_seen.size(1), A_seen.size(1)\n",
    "\n",
    "    # 1) 模型 & 优化器\n",
    "    Gmod = G(z_dim, a_dim, x_dim, g_hidden).to(device)\n",
    "    Dmod = D(x_dim, a_dim, d_hidden).to(device)\n",
    "    optG = torch.optim.Adam(Gmod.parameters(), lr=lr, betas=(0.5, 0.9))\n",
    "    optD = torch.optim.Adam(Dmod.parameters(), lr=lr, betas=(0.5, 0.9))\n",
    "\n",
    "    # 2) 数据\n",
    "    A_seen = A_seen.float().to(device)\n",
    "    dl = DataLoader(_FeatDS(X_seen, y_seen_sid),\n",
    "                    batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    # 3) 训练\n",
    "    for _ in tqdm(range(n_epochs), desc=desc):\n",
    "        for xb, yb_sid in dl:\n",
    "            xb, yb_sid = xb.to(device), yb_sid.to(device)\n",
    "            B = xb.size(0)\n",
    "\n",
    "            # -------------------------------\n",
    "            # D-step (Critic update)\n",
    "            # -------------------------------\n",
    "            for p in Dmod.parameters(): p.requires_grad_(True)\n",
    "            for p in Gmod.parameters(): p.requires_grad_(False)\n",
    "\n",
    "            for _ in range(n_critic):\n",
    "                with torch.enable_grad():                # 保证梯度开启\n",
    "                    a = A_seen[yb_sid]\n",
    "                    z = torch.randn(B, z_dim, device=device)\n",
    "                    x_fake = Gmod(z, a).detach()         # 只断开 G\n",
    "\n",
    "                    d_real = Dmod(xb, a).mean()\n",
    "                    d_fake = Dmod(x_fake, a).mean()\n",
    "                    gp     = grad_penalty(Dmod, xb, x_fake, a, gp_lambda)\n",
    "\n",
    "                    lossD = -(d_real - d_fake) + gp\n",
    "                    optD.zero_grad(set_to_none=True)\n",
    "                    lossD.backward()\n",
    "                    optD.step()\n",
    "\n",
    "            # -------------------------------\n",
    "            # G-step (Generator update)\n",
    "            # -------------------------------\n",
    "            for p in Dmod.parameters(): p.requires_grad_(False)\n",
    "            for p in Gmod.parameters(): p.requires_grad_(True)\n",
    "\n",
    "            with torch.enable_grad():\n",
    "                a = A_seen[yb_sid]\n",
    "                z = torch.randn(B, z_dim, device=device)\n",
    "                x_fake = Gmod(z, a)\n",
    "                lossG  = - Dmod(x_fake, a).mean()\n",
    "\n",
    "                optG.zero_grad(set_to_none=True)\n",
    "                lossG.backward()\n",
    "                optG.step()\n",
    "\n",
    "    return Gmod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0f2e417c-42c0-449a-b636-6471050a3820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synth_unseen(Gmod, A_unseen, n_per_class=300, z_dim=100):\n",
    "    Gmod.eval()\n",
    "    with torch.no_grad():\n",
    "        K = A_unseen.size(0)\n",
    "        z = torch.randn(K*n_per_class, z_dim, device=device)\n",
    "        a = A_unseen.float().to(device).repeat_interleave(n_per_class, 0)\n",
    "        Xsyn = Gmod(z, a).cpu()\n",
    "    return Xsyn  # [K*n, x_dim]\n",
    "\n",
    "class LinearSoftmax(nn.Module):\n",
    "    def __init__(self, in_dim, n_cls): super().__init__(); self.fc = nn.Linear(in_dim, n_cls)\n",
    "    def forward(self, x): return self.fc(x)\n",
    "\n",
    "def train_clf(X, y, n_cls, *, epochs=30, lr=1e-3, wd=1e-4, bs=256, seed=42, desc=\"CLS\"):\n",
    "    set_seed_all(seed)\n",
    "\n",
    "    # 1) 把输入统一成 torch 张量 + 正确 dtype/device\n",
    "    if not torch.is_tensor(X): X = torch.tensor(X)\n",
    "    if not torch.is_tensor(y): y = torch.tensor(y)\n",
    "    X = X.float().to(device)\n",
    "    y = y.long().to(device)\n",
    "\n",
    "    # 2) 简单线性分类器（和你之前的 LinearSoftmax 等价）\n",
    "    clf = nn.Sequential(nn.Linear(X.size(1), n_cls)).to(device)\n",
    "    opt = torch.optim.Adam(clf.parameters(), lr=lr, weight_decay=wd)\n",
    "    dl  = DataLoader(_FeatDS(X, y), batch_size=bs, shuffle=True, drop_last=True)\n",
    "\n",
    "    # 3) 训练：强制开启梯度 + 明确 train() + 自检\n",
    "    clf.train()\n",
    "    assert any(p.requires_grad for p in clf.parameters()), \"clf params require_grad=False ?\"\n",
    "\n",
    "    with torch.set_grad_enabled(True):            # 覆盖任何历史 set_grad_enabled(False)\n",
    "        for _ in tqdm(range(epochs), desc=desc):\n",
    "            for xb, yb in dl:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "                logits = clf(xb)                  # 不要 .detach() / .argmax()\n",
    "                loss   = F.cross_entropy(logits, yb)\n",
    "\n",
    "                # 运行前自检（若失败，可立刻定位）\n",
    "                assert logits.requires_grad, \"logits has no grad_fn (被detach/禁梯度了?)\"\n",
    "                assert loss.requires_grad,   \"loss has no grad_fn (梯度被全局关闭?)\"\n",
    "\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "074a2758-8d3d-4807-b146-4cc3b03094de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === f-CLSWGAN ④ 只调一次参（k=3，⏳） ===\n",
    "def fclswgan_tune_once_k3(resnet, S, *, seed=42):\n",
    "    set_seed_all(seed)\n",
    "    # 用第 0 折的 seen 类做 3 折伪 ZSL\n",
    "    k_tune = 0\n",
    "    train_loader, _, seen_cls, _ = make_dataloaders_for_fold(k_tune)\n",
    "    Xtr, ytr = extract_feats(train_loader, resnet)\n",
    "    parts = split_classes_k3(seen_cls, seed=seed)  # [C1, C2, C3]\n",
    "\n",
    "    # 两个超参各三值（作业要求）\n",
    "    grid = [(g_hidden, lr) for g_hidden in [1024, 2048, 3072] for lr in [5e-5, 1e-4, 2e-4]]\n",
    "\n",
    "    def eval_cfg(g_hidden, lr):\n",
    "        scores = []\n",
    "        for i in range(3):\n",
    "            val_cls = parts[i]\n",
    "            tr_cls  = parts[(i+1)%3] + parts[(i+2)%3]\n",
    "            tr_idx  = idx_of_classes(ytr.tolist(), tr_cls)\n",
    "            va_idx  = idx_of_classes(ytr.tolist(), val_cls)\n",
    "            X_tr, y_tr_gid = Xtr[tr_idx], ytr[tr_idx]\n",
    "            X_va, y_va_gid = Xtr[va_idx], ytr[va_idx]\n",
    "\n",
    "            # y -> seen 局部ID\n",
    "            train_seen_ids = sorted(list(map(int, set(tr_cls))))\n",
    "            gid2sid = {gid: sid for sid, gid in enumerate(train_seen_ids)}\n",
    "            y_tr_sid = torch.tensor([gid2sid[int(g)] for g in y_tr_gid], dtype=torch.long)\n",
    "\n",
    "            A_in_seen   = S[torch.tensor(train_seen_ids, dtype=torch.long)].cpu()\n",
    "            A_in_unseen = S[torch.tensor(val_cls,       dtype=torch.long)].cpu()\n",
    "\n",
    "            Gmod = train_wgan_seen(\n",
    "                X_tr, y_tr_sid, A_in_seen,\n",
    "                z_dim=100, g_hidden=g_hidden, d_hidden=2048,\n",
    "                lr=lr, n_epochs=40, batch_size=256, n_critic=5, gp_lambda=10.0, seed=seed,\n",
    "                desc=f\"GAN inner cfg(g={g_hidden},lr={lr}) fold{i+1}/3\"\n",
    "            )\n",
    "            X_syn = synth_unseen(Gmod, A_in_unseen, n_per_class=300, z_dim=100)\n",
    "            y_syn = torch.repeat_interleave(torch.tensor(val_cls, dtype=torch.long), repeats=300)\n",
    "            clf   = train_clf(X_syn, y_syn, n_cls=S.size(0), epochs=30, lr=1e-3, wd=1e-4, bs=256, seed=seed,\n",
    "                              desc=f\"CLS inner fold{i+1}/3\")\n",
    "            scores.append(acc_of(clf, X_va, y_va_gid))\n",
    "        return float(np.mean(scores))\n",
    "\n",
    "    best_cfg, best_score = None, -1.0\n",
    "    for g_hidden, lr in tqdm(grid, desc=\"Grid(k=3)\"):  # 每个配置 3 次小训练\n",
    "        s = eval_cfg(g_hidden, lr)\n",
    "        if s > best_score:\n",
    "            best_score = s\n",
    "            best_cfg = dict(g_hidden=g_hidden, lr=lr, d_hidden=2048,\n",
    "                            n_per_class=300, epochs_gan=40, batch_size=256,\n",
    "                            n_critic=5, gp_lambda=10.0)\n",
    "    print(f\"[TuneOnce@fold0] best={best_cfg} | inner-3fold acc={best_score:.4f}\")\n",
    "    return best_cfg, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cc7725a6-1e71-4886-a156-81ed5bb214b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === f-CLSWGAN ⑤ 10折（用固定 best_cfg，⏳） ===\n",
    "def fclswgan_run_10fold(resnet, S, best_cfg, *, seed=42, nw=0):\n",
    "    accs = []\n",
    "    for k in tqdm(range(10), desc=\"Outer 10-fold\"):\n",
    "        train_loader, test_loader, seen_cls, unseen_cls = make_dataloaders_for_fold(k, nw=nw)\n",
    "        X_tr, y_tr = extract_feats(train_loader, resnet)\n",
    "        X_te, y_te = extract_feats(test_loader,  resnet)\n",
    "\n",
    "        A_seen   = S[torch.tensor(seen_cls,   dtype=torch.long)].cpu()\n",
    "        A_unseen = S[torch.tensor(unseen_cls, dtype=torch.long)].cpu()\n",
    "\n",
    "        gid2sid = {gid: sid for sid, gid in enumerate(seen_cls)}\n",
    "        y_tr_sid = torch.tensor([gid2sid[int(g)] for g in y_tr.tolist()], dtype=torch.long)\n",
    "\n",
    "        # ⏳ 训练 GAN\n",
    "        Gmod = train_wgan_seen(\n",
    "            X_tr, y_tr_sid, A_seen,\n",
    "            z_dim=100,\n",
    "            g_hidden=best_cfg[\"g_hidden\"], d_hidden=best_cfg[\"d_hidden\"],\n",
    "            lr=best_cfg[\"lr\"], n_epochs=best_cfg[\"epochs_gan\"],\n",
    "            batch_size=best_cfg[\"batch_size\"], n_critic=best_cfg[\"n_critic\"],\n",
    "            gp_lambda=best_cfg[\"gp_lambda\"], seed=seed+k, desc=f\"GAN fold{k+1}\"\n",
    "        )\n",
    "\n",
    "        # 合成 + ⏳ 训练分类器\n",
    "        X_syn = synth_unseen(Gmod, A_unseen, n_per_class=best_cfg[\"n_per_class\"], z_dim=100)\n",
    "        y_syn = torch.repeat_interleave(torch.tensor(unseen_cls, dtype=torch.long),\n",
    "                                        repeats=best_cfg[\"n_per_class\"])\n",
    "        clf = train_clf(X_syn, y_syn, n_cls=S.size(0), epochs=30, lr=1e-3, wd=1e-4, bs=256,\n",
    "                        seed=seed+k, desc=f\"CLS fold{k+1}\")\n",
    "\n",
    "        acc = acc_of(clf, X_te, y_te)\n",
    "        accs.append(acc)\n",
    "        print(f\"Fold {k+1}: unseen acc = {acc:.4f}\")\n",
    "    mean_acc = float(np.mean(accs))\n",
    "    print(f\"\\n===> 10-fold mean unseen acc = {mean_acc:.4f}\")\n",
    "    return accs, mean_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2a21c7-1c33-4938-93b6-08fc8d81d2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d04da9f4fa254c0097b1acb37b2f8bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grid(k=3):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57bd35e3b5b14785a0810028d3cf26fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=1024,lr=5e-05) fold1/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b832beead2e416480da2b29173464c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold1/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e1d2776fba4ebf8c8d138b93d954df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=1024,lr=5e-05) fold2/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76612591ac740e3a725bad87a6ca3c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold2/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3b541c756045d9a18468ad5ba5a383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=1024,lr=5e-05) fold3/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcff611ce1e443eb8d80f83b1d177c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold3/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6149412f97e845f38f0b1d4e0a43ce84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=1024,lr=0.0001) fold1/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f2a9fd90c24d018bc46701d6587404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold1/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a32ad7ef1964d4a9c1829ecfcb3bf12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=1024,lr=0.0001) fold2/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ffd09522ccc44929d9097e21a71f860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold2/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f8ba03097c4e7082d9f7c8a68ac4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=1024,lr=0.0001) fold3/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36444511e735422b9240dfa0a54d096f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold3/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13fdea8dbcf479d97e100c989c7c775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=1024,lr=0.0002) fold1/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a238be5e16d446db8703fba25dd1517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold1/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174e63a124d045198031a4696b9372a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=1024,lr=0.0002) fold2/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6bb3ab107954b72bce3dbad9726a09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold2/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4308080794224fc7b49f3351ab4a8137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=1024,lr=0.0002) fold3/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfdfbd3330cb469da3fb0b29543b2b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold3/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ae4195368a4c168c14d3991a9f8b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=2048,lr=5e-05) fold1/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf039233fc214aeb9e5be4e6a753ff79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold1/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1acb9052cfe44e9ad5e2d99e04fc231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=2048,lr=5e-05) fold2/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1cf16100854565b6f313da886d9759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold2/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d33f14f001b4f4ea8188229823b448c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=2048,lr=5e-05) fold3/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252e43b8fed84abd8f610870f915c6b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold3/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8db4e097aa4aa6b8f0b063312df504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=2048,lr=0.0001) fold1/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a270e95695af47738c58f99fe4884d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold1/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa2c727c1ff49fb9a206e40765fac60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=2048,lr=0.0001) fold2/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541c3cb173554772bbff458c2e0f7316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold2/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7dc219e54604668992b1ebd72da3901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=2048,lr=0.0001) fold3/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dbd9062dad7406090b92bf909d6027d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold3/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b18628cdf0244f58666fce1cfd400af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=2048,lr=0.0002) fold1/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d313831ff3d14a45a46cf509924fbcd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold1/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4320706cceb4422b3795bf29a47bb81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=2048,lr=0.0002) fold2/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc18d70c5204592b301c9aeeaa250b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold2/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b835ef2b4a4e9c84afb3f8f6a07787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=2048,lr=0.0002) fold3/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a2b99e723b402186c6e9020e97ef9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold3/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10199c38cbac4581b1c7bd9a1fe7bb25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=3072,lr=5e-05) fold1/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83dda5f2e70341448b6e007218b47a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold1/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b6006ee8e14e1aa88bd105786e8722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=3072,lr=5e-05) fold2/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25988b5b658d4006bf8f4d62383effb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold2/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f22a58cc14440db040c4af35564f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=3072,lr=5e-05) fold3/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd56ce750334f0b8bf2e5b62985ed7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold3/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae9495e0637448395406c8fe26efd4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=3072,lr=0.0001) fold1/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f5d7ca69a94b98be080ac321bc4fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold1/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e34856e7fea4b00b61a64c85a8a966b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=3072,lr=0.0001) fold2/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762b38a4ea98417da14805db398cc8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold2/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a4a517f921476297f7815eccc0b656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=3072,lr=0.0001) fold3/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69478aea8b341e58c5589ccc5af485d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold3/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af29234469824650b70d7420295dc2fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=3072,lr=0.0002) fold1/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c86d19af6a4a77baaa50af0ebbcaac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold1/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45146d30a344dd2948ebee2ec64b43d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=3072,lr=0.0002) fold2/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c575064ab0d413b86c0c3440a03cb11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLS inner fold2/3:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ecafee79224e5f91fcca0bbf051979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN inner cfg(g=3072,lr=0.0002) fold3/3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_cfg, inner_acc = fclswgan_tune_once_k3(resnet, S, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889b1498-ebf8-42b1-a2de-6b0efd5c6d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait for loading\n",
    "accs, mean_acc = fclswgan_run_10fold(resnet, S, best_cfg, seed=42, nw=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
